# -*- coding: utf-8 -*-
"""Online_Proctoring_API.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1gsZ5u1A93ml7gVb_iZfwcQiVWI7w74Os
"""

"""###  Note to run this API use your own IP Address"""

from flask import Flask, jsonify, request
import cv2
from mtcnn import MTCNN
import threading
import time

app = Flask(__name__)

detector = MTCNN()

# Open the default camera
cap = cv2.VideoCapture(0)

# Create a threading lock to synchronize access to the camera frames
lock = threading.Lock()

# Flag to indicate if the popup window should be shown
show_popup = False

def display_popup():
    global show_popup

    start_time = time.time()
    session_duration = 1  # Default session duration (in seconds)

    while True:
        if show_popup:
            ret, frame = cap.read()
            img = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
            results = detector.detect_faces(img)
            count = len(results)

            if count > 1 or count < 1:
                cv2.imshow("Detected Faces", frame)

        # Check if session duration has elapsed
        elapsed_time = time.time() - start_time
        if elapsed_time >= session_duration:
            break

        # Exit the loop if 'q' is pressed
        if cv2.waitKey(1) & 0xFF == ord('q'):
            break

    # Release the camera and destroy the OpenCV windows
    cap.release()
    cv2.destroyAllWindows()



@app.route('/', methods=['GET'])
def hello():
    return "Hello, this is a face detection API!"


@app.route('/face_count', methods=['GET'])
def get_face_count():
    global show_popup

    session_duration = request.args.get('session_duration')
    if session_duration is None:
        session_duration = 20
    else:
        session_duration = int(session_duration)

    # Acquire the lock to prevent simultaneous access to the camera frames
    lock.acquire()

    start_time = time.time()
    end_time = start_time + session_duration

    while time.time() < end_time:
        ret, frame = cap.read()
        img = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        results = detector.detect_faces(img)
        count = len(results)

        if count > 1 or count < 1:
            show_popup = True
            if count < 1:
                # Capture an image if no face is detected
                timestamp = time.strftime("%Y%m%d-%H%M%S")
                filename = f"no_face_{timestamp}.jpg"
                cv2.imwrite(filename, frame)
                lock.release()
                return jsonify({'message': f'No face detected. Image captured: {filename}'})

            if count > 1:
                # Capture an image if multiple faces are detected
                timestamp = time.strftime("%Y%m%d-%H%M%S")
                filename = f"multiple_faces_{timestamp}.jpg"
                cv2.imwrite(filename, frame)
                lock.release()
                return jsonify({'message': f'Multiple faces detected. Image captured: {filename}'})

    show_popup = False
    lock.release()

    return jsonify({'face_count': count})


if __name__ == '__main__':
    # Start the thread for displaying the popup window
    popup_thread = threading.Thread(target=display_popup)
    popup_thread.daemon = True
    popup_thread.start()

    app.run(host='192.168.18.252', port=5000)



from flask import Flask, jsonify, request, Response
import speech_recognition as sr

app = Flask(__name__)

@app.route('/', methods=['GET'])
def hello():
    return "Hello, this is a voice transcription API!"

@app.route('/transcribe', methods=['GET'])
def transcribe():
    # Create a new instance of the SpeechRecognition class
    r = sr.Recognizer()
    # Open the default microphone
    with sr.Microphone() as source:
        print("Listening...")

        try:
            # Listen for speech and store it in an audio file
            audio = r.listen(source)

            # Use Google's speech recognition API to transcribe the audio
            text = r.recognize_google(audio)
            print(f"You said: {text}")

            # Create a JSON response with the transcription
            response = jsonify({'transcription': text})
            # Set the response status code to 200 (OK)
            response.status_code = 200

            # End the HTTP request by returning the response
            return response
                
        except sr.UnknownValueError:
            print("Could not understand")
        except sr.RequestError as e:
            print(f"Could not request results from Google Speech Recognition service; {e}")

    # If no transcription is available, create a JSON response with None
    response = jsonify({'transcription': None})
    # Set the response status code to 200 (OK)
    response.status_code = 200

    # End the HTTP request by returning the response
    return response

if __name__ == '__main__':
    app.run(host='192.168.18.252', port=5000)

"""### To give session duration as a parameter for your specific case. Look at code below

@app.route('/transcribe', methods=['GET'])
def transcribe():
    session_duration = request.args.get('session_duration')
    if not session_duration:
        session_duration = 900
    else:
        session_duration = int(session_duration)

http://localhost:5000/transcribe?session_duration=1800
"""